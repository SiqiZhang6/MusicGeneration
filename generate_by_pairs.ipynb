{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worddict {(32, 1, 5, 4, 4): 0, (32, 0, 5, 12, 4): 1, (39, 0, 5, 20, 4): 2, (39, 2, 5, 28, 4): 3, (41, 1, 5, 4, 5): 4, (41, 0, 5, 12, 5): 5, (39, 2, 5, 20, 5): 6, (37, 1, 5, 4, 6): 7, (37, 0, 5, 12, 6): 8, (36, 0, 5, 20, 6): 9, (36, 2, 5, 28, 6): 10, (34, 1, 5, 4, 7): 11, (34, 0, 5, 12, 7): 12, (32, 2, 5, 20, 7): 13, (39, 1, 5, 4, 8): 14, (39, 0, 5, 12, 8): 15, (37, 0, 5, 20, 8): 16, (37, 2, 5, 28, 8): 17, (36, 1, 5, 4, 9): 18, (36, 0, 5, 12, 9): 19, (34, 2, 5, 20, 9): 20, (39, 1, 5, 4, 10): 21, (39, 0, 5, 12, 10): 22, (37, 0, 5, 20, 10): 23, (37, 2, 5, 28, 10): 24, (36, 1, 5, 4, 11): 25, (36, 0, 5, 12, 11): 26, (34, 2, 5, 20, 11): 27, (32, 1, 5, 4, 12): 28, (32, 0, 5, 12, 12): 29, (39, 0, 5, 20, 12): 30, (39, 2, 5, 28, 12): 31, (41, 1, 5, 4, 13): 32, (41, 0, 5, 12, 13): 33, (39, 2, 5, 20, 13): 34, (37, 1, 5, 4, 14): 35, (37, 0, 5, 12, 14): 36, (36, 0, 5, 20, 14): 37, (36, 2, 5, 28, 14): 38, (34, 1, 5, 4, 15): 39, (34, 0, 5, 12, 15): 40, (32, 2, 5, 20, 15): 41}\n",
      "tensor([ 0.6113, -0.5005,  0.2525,  1.1769,  0.5059, -0.3477, -1.0188, -0.0687,\n",
      "        -0.8889,  0.3298,  0.0123,  0.3309,  0.3749,  0.9867,  0.2013, -0.2436,\n",
      "         0.7583, -0.1901, -0.4448, -0.6583,  1.6095,  0.3690, -0.2633, -0.3454,\n",
      "         0.8635, -0.0871,  0.1220,  0.3558, -1.3682,  1.0776, -0.0907,  0.7534,\n",
      "         0.5826, -0.2451, -0.7978, -1.2742, -0.5938,  0.7689, -0.9320,  0.4459,\n",
      "         1.1965,  0.3974,  0.3084,  1.0210, -0.1064,  0.2070,  0.5195,  0.1794,\n",
      "        -0.9399, -2.4802,  0.3362,  0.2053, -2.7136, -0.7103,  1.4932, -0.5472,\n",
      "        -1.4127,  0.2483, -0.3300, -0.5091,  1.0074, -1.9698,  0.6237, -0.3286,\n",
      "        -0.1833,  2.0011,  0.1478, -0.3333, -0.3910, -0.7307, -0.1568,  0.0603,\n",
      "        -0.6336,  0.7367,  0.5223,  0.1548,  0.0396,  0.5921, -1.2140, -1.0796,\n",
      "         0.5605,  0.6071, -1.0189,  0.3438, -0.6675,  0.9815, -0.5228, -0.3138,\n",
      "        -0.8614,  0.9604, -0.2417,  1.2142,  0.4903,  0.3646,  0.1105,  2.2152,\n",
      "         0.1384, -3.0123,  0.0672,  1.5617, -1.2714,  0.5780,  0.1700,  1.5488,\n",
      "        -0.2914,  0.5574,  1.4037, -1.1246,  0.3592,  1.0761, -0.7779, -0.0837,\n",
      "        -1.4536, -2.1429, -0.2828, -0.0969, -0.6445, -1.9325, -0.2311,  0.0267,\n",
      "         2.2303,  0.4956, -2.4613, -0.0228,  1.3463,  1.2992, -0.5779,  1.4148],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import math, copy, time\n",
    "import torch, math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor,layer_norm\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "import preprocessing,note2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 512\n",
    "nhead = 8\n",
    "nlayer=6\n",
    "  # nlayer = 6\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "  # original Training parameters\n",
    "  # lr = 0.00001\n",
    "  # epochs = 2000\n",
    "epochs = 200\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main functions###\n",
    "def getDataLoader(data, batch_size):\n",
    "  # loaded=torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "  return torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "def loadData(allTokensEvents,num_bar):\n",
    "  X = []\n",
    "  y = []\n",
    "  for song in allTokensEvents:\n",
    "    for i in range(len(song) - num_bar):\n",
    "      src_bar = []\n",
    "      for num in range(num_bar):\n",
    "        src_bar += song[i + num]\n",
    "      tgt_bar = song[i + num_bar] + [2]\n",
    "      X.append(src_bar)\n",
    "      y.append(tgt_bar)\n",
    "\n",
    "  max_src_bar_len = len(max(X, key = len))\n",
    "  max_tgt_bar_len = len(max(y, key = len))\n",
    "\n",
    "  data = []\n",
    "  for i in range(len(X)):\n",
    "    src_notes = torch.LongTensor(X[i])\n",
    "    tgt_notes = torch.LongTensor(y[i])\n",
    "\n",
    "    src_full = torch.full((max_src_bar_len,), fill_value = 0)\n",
    "    tgt_full = torch.full((max_tgt_bar_len,), fill_value = 0)\n",
    "\n",
    "    src_full[:len(src_notes)] = src_notes\n",
    "    tgt_full[:len(tgt_notes)] = tgt_notes\n",
    "    data.append([src_full, tgt_full])\n",
    "  dataloader_combined = getDataLoader(data, 2)\n",
    "  return dataloader_combined\n",
    "# clones\n",
    "def clone(module, N):\n",
    "  \"Produce N identical layers.\"\n",
    "  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "# mask\n",
    "def subsequent_mask(size):\n",
    "  attention_shape=(1,size, size)\n",
    "  subsequent_mask= np.triu(np.ones(attention_shape),k=1).astype('uint8')\n",
    "  return torch.from_numpy(1-subsequent_mask)\n",
    "# attentionðŸŽ¶#\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main classes###\n",
    "# layernorm\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x[0]\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "# embedding\n",
    "class Embedding(nn.Module):\n",
    "  def __init__(self, contextsize,embedding_dim, vocab):\n",
    "    super(Embedding,self).__init__()\n",
    "    self.lut,self.idx=note2vec.embed(contextsize,embedding_dim, vocab)\n",
    "    self.embed_dim=embedding_dim\n",
    "  def forward(self, input):\n",
    "    return torch.tensor([[(self.lut[self.idx[tuple(i.tolist())]]*math.sqrt(self.embed_dim)).tolist() for i in input]])\n",
    "  def unembed(self,input):\n",
    "    return torch.tensor([list(self.idx.keys())[i] for i in input])\n",
    "  def getidx(self,input):\n",
    "    return torch.tensor([self.idx[tuple(i.tolist())]for i in input])\n",
    "# positional encoding\n",
    "class PosEncoding(nn.Module):\n",
    "  def __init__(self, embedding_dim, dropout,max_len):\n",
    "    super(PosEncoding,self).__init__()\n",
    "    self.dropout=nn.Dropout(p=dropout)\n",
    "    pe=torch.zeros(max_len, embedding_dim)\n",
    "    position=torch.arange(0,max_len).unsqueeze(1)\n",
    "    half=torch.exp(torch.arange(0, embedding_dim, 2)* -(math.log(1000.0/embedding_dim)))\n",
    "    pe[:,0::2]=torch.sin(position*half)\n",
    "    pe[:,1::2]=torch.cos(position*half)\n",
    "    pe=pe.unsqueeze(0)\n",
    "    ####\n",
    "    self.register_buffer('pe',pe)\n",
    "  def forward(self,input):\n",
    "    input=input+Variable(self.pe[:,:input.size(1)],requires_grad=False)\n",
    "    return self.dropout(input)\n",
    "# sublayer connection\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, nhead, embedding_dim, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert embedding_dim % nhead == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = embedding_dim // nhead\n",
    "        self.h = nhead\n",
    "        temlinear=nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.linears = clone(temlinear, 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        query=torch.tensor([query.tolist()])\n",
    "        key=torch.tensor([key.tolist()])\n",
    "        value=torch.tensor([value.tolist()])\n",
    "        # print(\"q\",query,query.shape)\n",
    "        # print(\"k\",key,key.shape)\n",
    "        # print(\"v\",value,value.shape)\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        \n",
    "        lx=[l(x) for l, x in zip(self.linears, (query, key, value))]\n",
    "        # print(\"lx\",lx,[l.shape for l in lx])\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "#FFW#\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, embedding_dim, dim_feedforward, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(embedding_dim, dim_feedforward)\n",
    "        self.w_2 = nn.Linear(dim_feedforward, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "# encoder\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, encoderlayer, nhead):\n",
    "    super(Encoder,self).__init__()\n",
    "    self.layers=clone(encoderlayer,nhead)\n",
    "    self.norm=LayerNorm(encoderlayer.size)\n",
    "  def forward(self, encoder_input,mask):\n",
    "    for layer in self.layers:\n",
    "      encoder_input=layer(encoder_input,mask)\n",
    "    return self.norm(encoder_input)\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder = self-attn + feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clone(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        # print(\"encoderQVK\",x,x.shape)\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        # print(\"postx\",x,x.shape)\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "# decoder\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, decoderlayer, N):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.layers = clone(decoderlayer, N)\n",
    "    self.norm = LayerNorm(decoderlayer.size)\n",
    "  def forward(self, decoder_input,encoder_input,src_mask,tgt_mask):\n",
    "    for layer in self.layers:\n",
    "      decoder_input = layer(decoder_input, encoder_input, src_mask, tgt_mask)\n",
    "    return self.norm(decoder_input)\n",
    "    \n",
    "class EncoderDecoderLayer(nn.Module):\n",
    "  def __init__(self,size, self_attn,src_attn,feedforward,dropout):\n",
    "    super(EncoderDecoderLayer, self).__init__()\n",
    "    self.size=size\n",
    "    self.self_attn=self_attn\n",
    "    self.src_attn=src_attn\n",
    "    self.feedforward=feedforward\n",
    "    self.sublayer=clone(SublayerConnection(size, dropout),3)\n",
    "  def forward(self, decoder_input,encoder_input,src_mask,tgt_mask):\n",
    "    d=decoder_input\n",
    "    d = self.sublayer[0](d, lambda d: self.self_attn(d, d, d, tgt_mask))\n",
    "    d = self.sublayer[1](d, lambda d: self.src_attn(d, encoder_input, encoder_input, src_mask))\n",
    "    return self.sublayer[2](d, self.feedforward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class MusicTransformer(nn.Module):\n",
    "  def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "    super(MusicTransformer, self).__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.src_embed = src_embed\n",
    "    self.tgt_embed = tgt_embed\n",
    "    self.generator = generator\n",
    "  def create_mask(self, src, tgt):\n",
    "    tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.shape[1])\n",
    "    src_padding_mask = (src == 0)\n",
    "    tgt_padding_mask = (tgt == 0)\n",
    "    return tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "  def maskall(self,size):\n",
    "    allones=torch.zeros(1,size,size)\n",
    "    return (allones!=0)\n",
    "  def forward(self, src, tgt,train):\n",
    "    \"Take in and process masked src and target sequences.\"\n",
    "    if train:\n",
    "      # src_mask=(src == 0)\n",
    "      src_mask=None\n",
    "      # src_mask=None\n",
    "      # for i in range(src_mask.size(1)):\n",
    "      #   src_mask[0][i]=[1]if s=='True' else 0 for s in src_mask[0][i]]\n",
    "      # src_mask=torch.matmul(src_mask, src_mask.transpose(-2, -1))\n",
    "      # tgt_mask =subsequent_mask(tgt.shape[1])\n",
    "      \n",
    "      tgt_mask =subsequent_mask(len(tgt))\n",
    "      # tgt_mask=None\n",
    "      # tgt_mask = torch.transformer.generate_square_subsequent_mask(tgt.shape[1])\n",
    "      test=self.decode(self.encode(src, src_mask), src_mask,tgt,tgt_mask)\n",
    "      # print(\"previewtrain\",test,test.shape)\n",
    "      # return self.decode(self.encode(src, src_mask), src_mask,tgt,tgt_mask)\n",
    "      return torch.tensor([test.tolist()])\n",
    "  \n",
    "    else:\n",
    "      # tgt_mask=self.maskall(tgt.shape[1])\n",
    "      tgt_mask=None\n",
    "      # print(tgt_mask)\n",
    "      test1=self.decode(self.encode(src, None), None,tgt,tgt_mask)\n",
    "      # return self.decode(self.encode(src, None), None,tgt,tgt_mask)\n",
    "      return torch.tensor([test1.tolist()])\n",
    "\n",
    "    # return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "    \n",
    "  def encode(self, src, src_mask):\n",
    "    return self.encoder(self.src_embed[0](src), src_mask)\n",
    "    \n",
    "  def decode(self, memory, src_mask,tgt,tgt_mask):\n",
    "    return self.decoder(self.tgt_embed[0](tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train and generation ###\n",
    "# not used\n",
    "def train_epoch(iterations, model, lossfn):\n",
    "  start = time.time()\n",
    "  total_tokens = 0\n",
    "  total_loss = 0\n",
    "  tokens = 0\n",
    "  for i, batch in enumerate(iterations):\n",
    "    out = model.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "    loss = lossfn(out, batch.trg_y, batch.ntokens)\n",
    "    total_loss += loss\n",
    "    total_tokens += batch.ntokens\n",
    "    tokens += batch.ntokens\n",
    "    if i % 10 == 1:\n",
    "      elapsed = time.time() - start\n",
    "      print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %(i, loss / batch.ntokens, tokens / elapsed))\n",
    "      start = time.time()\n",
    "      tokens = 0\n",
    "    return total_loss / total_tokens\n",
    "\n",
    "# generation\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.vocab=vocab\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"softmax\",F.log_softmax(self.proj(x), dim=-1))\n",
    "        # newthing=nn.Linear(x.size(1),self.vocab)\n",
    "        # print(newthing(x),newthing(x).size())\n",
    "        # return F.log_softmax(newthing(x), dim=1)\n",
    "        return F.softmax(self.proj(x), dim=1)\n",
    "        # return F.log_softmax(self.proj(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab,nlayer, embedding_dim,dim_feedforward,nhead,dropout,max_len):\n",
    "  c = copy.deepcopy\n",
    "  attn = MultiHeadedAttention(nhead, embedding_dim)\n",
    "  ff = PositionwiseFeedForward(embedding_dim, dim_feedforward, dropout)\n",
    "  position = PosEncoding(embedding_dim, dropout, max_len)\n",
    "  \n",
    "  src_embed=nn.Sequential(Embedding(2,embedding_dim, src_vocab), c(position))\n",
    "  tgt_embed=nn.Sequential(Embedding(2,embedding_dim, tgt_vocab), c(position))\n",
    "  model = MusicTransformer(\n",
    "        Encoder(EncoderLayer(embedding_dim, c(attn), c(ff), dropout), nlayer),\n",
    "        Decoder(EncoderDecoderLayer(embedding_dim, c(attn), c(attn), c(ff), dropout), nlayer),\n",
    "        src_embed,\n",
    "        tgt_embed,\n",
    "        Generator(embedding_dim,max_len))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "  # for p in model.parameters():\n",
    "  #   if p.dim() > 1:\n",
    "  #     nn.init.xavier_uniform(p)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(epochs,dataloader, model):\n",
    "  for epoch in range(1, 1 + epochs):\n",
    "    train_epoch_loss = 0\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.train()\n",
    "    for i, (src, tgt) in enumerate(dataloader):\n",
    "      optimizer.zero_grad()\n",
    "      # print(\"src,tgt\",src,tgt)\n",
    "      output = model(src, tgt,True)\n",
    "      # print(\"predout\",output,output.size())\n",
    "      newoutput=model.generator(output)\n",
    "      # output=torch.tensor([output.tolist()])\n",
    "      # print(\"output\",newoutput,newoutput.size())\n",
    "      final_token=torch.argmax(newoutput, dim = 2).data\n",
    "      # print(\"finaltoken\",final_token,final_token.shape)\n",
    "      target=model.tgt_embed[0].getidx(tgt)\n",
    "      # target=model.tgt_embed[0].forward(tgt)\n",
    "      # print(\"tgt\",target,target.shape)\n",
    "      a=newoutput.contiguous().view(-1, newoutput.size(-1))\n",
    "      b=target.contiguous().view(-1) \n",
    "      # print(\"a\",a,a.shape,\"b\",b,b.shape)\n",
    "      loss = criterion(a, b)\n",
    "      loss.backward()\n",
    "      # print(\"loss\",loss.item())\n",
    "      \n",
    "      optimizer.step()\n",
    "\n",
    "      train_epoch_loss += loss.item()\n",
    "     \n",
    "      finalconverted=model.src_embed[0].unembed(final_token[0])\n",
    "      # print(\"final\",finalconverted,\"target\",tgt)\n",
    "      num_correct += torch.sum(finalconverted == tgt)\n",
    "      num_total+=len(target)\n",
    "    model.eval()\n",
    "    outputs.append(output)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_acc.append(num_correct/num_total)\n",
    "    if epoch % 2 == 0:\n",
    "      print('EPOCH %i' % (epoch))\n",
    "      print(\"Train loss: %f\" % (train_loss[epoch - 1]))\n",
    "      print(\"Train acc: %f\" % (train_acc[epoch - 1]))\n",
    "      torch.save(model.state_dict(), './data/modelStates/note2veclowerlr')\n",
    "      if epoch % 4 == 0:\n",
    "        final_token=torch.argmax(newoutput, dim = 2).data\n",
    "        finalconverted=model.src_embed[0].unembed(final_token[0])\n",
    "        print(\"Predictions:\",finalconverted)\n",
    "        # print(\"Predictions:\", torch.argmax(output, dim = 2))#change to softmax\n",
    "        # encoderHeat(testMod,6,2,tokenEvents)\n",
    "        # decoderHeat(testMod,6,2,tokenEvents,tokenEvents)\n",
    "        print(\"Target:\", tgt)\n",
    "  torch.save(model.state_dict(),'./data/modelStates/note2veclowerlr')\n",
    "\n",
    "def makeTensor(X,y,max_src_bar_len,max_tgt_bar_len):\n",
    "  data = []\n",
    "  for i in range(len(X)):\n",
    "    src_notes = torch.LongTensor(X[i])\n",
    "    tgt_notes = torch.LongTensor(y[i])\n",
    "\n",
    "    src_full = torch.full((max_src_bar_len,), fill_value = 0)\n",
    "    tgt_full = torch.full((max_tgt_bar_len,), fill_value = 0)\n",
    "\n",
    "    src_full[:len(src_notes)] = src_notes\n",
    "    tgt_full[:len(tgt_notes)] = tgt_notes\n",
    "    data.append([src_full, tgt_full])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "note2vecds [[tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5],\n",
      "        [41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]]), tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])], [tensor([[41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5],\n",
      "        [37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]]), tensor([[34,  1,  5],\n",
      "        [34,  0,  5],\n",
      "        [32,  2,  5]])], [tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5],\n",
      "        [34,  1,  5],\n",
      "        [34,  0,  5],\n",
      "        [32,  2,  5]]), tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]])], [tensor([[34,  1,  5],\n",
      "        [34,  0,  5],\n",
      "        [32,  2,  5],\n",
      "        [39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]]), tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]])], [tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5],\n",
      "        [36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]]), tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]])], [tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5],\n",
      "        [39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]]), tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]])], [tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5],\n",
      "        [36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]]), tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5]])], [tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5],\n",
      "        [32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5]]), tensor([[41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]])], [tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5],\n",
      "        [41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]]), tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])]]\n",
      "x1 [tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5],\n",
      "        [41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]]), tensor([[41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5],\n",
      "        [37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]]), tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5],\n",
      "        [34,  1,  5],\n",
      "        [34,  0,  5],\n",
      "        [32,  2,  5]]), tensor([[34,  1,  5],\n",
      "        [34,  0,  5],\n",
      "        [32,  2,  5],\n",
      "        [39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]]), tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5],\n",
      "        [36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]]), tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5],\n",
      "        [39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]]), tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5],\n",
      "        [36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]]), tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5],\n",
      "        [32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5]]), tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5],\n",
      "        [41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]])]\n",
      "y1 [tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]]), tensor([[34,  1,  5],\n",
      "        [34,  0,  5],\n",
      "        [32,  2,  5]]), tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]]), tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]]), tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]]), tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]]), tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5]]), tensor([[41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]]), tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])]\n",
      "343\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "data_path1 = './data/testmidi.mid'\n",
    "# data_path1 = './data/bach/fp-4bou.mid'\n",
    "data_path2 = './data/bach/fp-3sar.mid'\n",
    "barnum=2\n",
    "tokenEvents1=preprocessing.tokenizeSOSEOS(data_path1)\n",
    "tokenEvents2=preprocessing.tokenizeSOSEOS(data_path2)\n",
    "initbarnum=tokenEvents1[0][-1]\n",
    "initpos=tokenEvents1[0][-2]\n",
    "print(initbarnum,initpos)\n",
    "# tokenEvents1=[tuple(a) for a in tokenEvents1]\n",
    "# tokenEvents1=note2vec.embed(2,128,tokenEvents1)\n",
    "# tokenEvents1=[x[:-1] for x in tokenEvents1]\n",
    "# numbarXY1=preprocessing.note2vecNote(tokenEvents1,5)\n",
    "\n",
    "numbarXY1=preprocessing.note2vecNumBarRelative([x[:-2] for x in tokenEvents1],2)\n",
    "numbarXY2=preprocessing.note2vecNumBarRelative(tokenEvents2,2)\n",
    "print(\"note2vecds\",numbarXY1)\n",
    "X1=[l[0] for l in numbarXY1]\n",
    "Y1=[l[1] for l in numbarXY1]\n",
    "X2=[l[0] for l in numbarXY2]\n",
    "Y2=[l[1] for l in numbarXY2]\n",
    "print(\"x1\",X1)\n",
    "print(\"y1\",Y1)\n",
    "# print(\"x2\",X2)\n",
    "# print(\"y2\",Y2)\n",
    "# maxbarlen=len(max(X1+Y1, key = len))//5\n",
    "# print(maxbarlen)\n",
    "\n",
    "# data1=[[torch.LongTensor(X1[i]),torch.LongTensor(Y1[i])]for i in range(len(X1))]\n",
    "# data2=[[torch.LongTensor(X2[i]),torch.LongTensor(Y2[i])]for i in range(len(X2))]\n",
    "# dataloader=getDataLoader(data1,1)\n",
    "# dataloader=getDataLoader(X1,1)\n",
    "\n",
    "\n",
    "alltokens=[]\n",
    "alltokens+=[tok for tok in tokenEvents1 if tok not in alltokens]\n",
    "alltokens+=[tok for tok in tokenEvents2 if tok not in alltokens]\n",
    "print(len(alltokens))\n",
    "\n",
    "# num_events = len(alltokens)\n",
    "num_events=len(tokenEvents1)\n",
    "print(num_events)\n",
    "embedding_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class noteDataset():\n",
    "    def __init__(self,numbarXY) -> None:\n",
    "        self.x=[l[0] for l in numbarXY]\n",
    "        self.y=[l[1] for l in numbarXY]\n",
    "        self.n_samples=len(numbarXY)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worddict {(32, 1, 5): 0, (32, 0, 5): 1, (39, 0, 5): 2, (39, 2, 5): 3, (41, 1, 5): 4, (41, 0, 5): 5, (37, 1, 5): 6, (37, 0, 5): 7, (36, 0, 5): 8, (36, 2, 5): 9, (34, 1, 5): 10, (34, 0, 5): 11, (32, 2, 5): 12, (39, 1, 5): 13, (37, 2, 5): 14, (36, 1, 5): 15, (34, 2, 5): 16}\n",
      "worddict {(32, 1, 5): 0, (32, 0, 5): 1, (39, 0, 5): 2, (39, 2, 5): 3, (41, 1, 5): 4, (41, 0, 5): 5, (37, 1, 5): 6, (37, 0, 5): 7, (36, 0, 5): 8, (36, 2, 5): 9, (34, 1, 5): 10, (34, 0, 5): 11, (32, 2, 5): 12, (39, 1, 5): 13, (37, 2, 5): 14, (36, 1, 5): 15, (34, 2, 5): 16}\n"
     ]
    }
   ],
   "source": [
    "#making testmod\n",
    "# Metrics to evaluate model\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "outputs = []\n",
    "# maxtok=max(tokenEvents)[0]\n",
    "# print(maxtok)\n",
    "src_vocab=[]\n",
    "for x in [a[:-2] for a in tokenEvents1]:\n",
    "    if x not in src_vocab:\n",
    "        src_vocab.append(x)\n",
    "src_vocab=list(src_vocab)\n",
    "# tgt_vocab=list(src_vocab)\n",
    "\n",
    "# print(\"srcvocabs\",src_vocab)\n",
    "# print(\"tgtvocabs\",tgt_vocab)\n",
    "testMod=make_model(src_vocab,src_vocab,nlayer, embedding_dim,dim_feedforward,nhead,dropout,max_len=len(src_vocab))\n",
    "optimizer = torch.optim.Adam(testMod.parameters(), lr= lr)\n",
    "#check src and tgt embedding\n",
    "# print(\"src\",testMod.src_embed.size(),\"tgt\",testMod.tgt_embed.size())\n",
    "# print(inputx,src_embed(inputx),tgt_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2\n",
      "Train loss: 25.169168\n",
      "Train acc: 1.875000\n",
      "EPOCH 4\n",
      "Train loss: 23.180627\n",
      "Train acc: 2.531250\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 6\n",
      "Train loss: 21.497553\n",
      "Train acc: 2.843750\n",
      "EPOCH 8\n",
      "Train loss: 20.516014\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 10\n",
      "Train loss: 20.055729\n",
      "Train acc: 3.000000\n",
      "EPOCH 12\n",
      "Train loss: 19.828285\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 14\n",
      "Train loss: 19.694635\n",
      "Train acc: 3.000000\n",
      "EPOCH 16\n",
      "Train loss: 19.626167\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 18\n",
      "Train loss: 19.570678\n",
      "Train acc: 3.000000\n",
      "EPOCH 20\n",
      "Train loss: 19.535513\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 22\n",
      "Train loss: 19.505255\n",
      "Train acc: 3.000000\n",
      "EPOCH 24\n",
      "Train loss: 19.482360\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 26\n",
      "Train loss: 19.463715\n",
      "Train acc: 3.000000\n",
      "EPOCH 28\n",
      "Train loss: 19.448145\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 30\n",
      "Train loss: 19.435938\n",
      "Train acc: 3.000000\n",
      "EPOCH 32\n",
      "Train loss: 19.423866\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 34\n",
      "Train loss: 19.414593\n",
      "Train acc: 3.000000\n",
      "EPOCH 36\n",
      "Train loss: 19.406044\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 38\n",
      "Train loss: 19.399919\n",
      "Train acc: 3.000000\n",
      "EPOCH 40\n",
      "Train loss: 19.392570\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 42\n",
      "Train loss: 19.386469\n",
      "Train acc: 3.000000\n",
      "EPOCH 44\n",
      "Train loss: 19.381885\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 46\n",
      "Train loss: 19.377444\n",
      "Train acc: 3.000000\n",
      "EPOCH 48\n",
      "Train loss: 19.372171\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 50\n",
      "Train loss: 19.368565\n",
      "Train acc: 3.000000\n",
      "EPOCH 52\n",
      "Train loss: 19.364632\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 54\n",
      "Train loss: 19.362015\n",
      "Train acc: 3.000000\n",
      "EPOCH 56\n",
      "Train loss: 19.359036\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 58\n",
      "Train loss: 19.356851\n",
      "Train acc: 3.000000\n",
      "EPOCH 60\n",
      "Train loss: 19.353542\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 62\n",
      "Train loss: 19.351611\n",
      "Train acc: 3.000000\n",
      "EPOCH 64\n",
      "Train loss: 19.348958\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 66\n",
      "Train loss: 19.347434\n",
      "Train acc: 3.000000\n",
      "EPOCH 68\n",
      "Train loss: 19.345567\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 70\n",
      "Train loss: 19.343784\n",
      "Train acc: 3.000000\n",
      "EPOCH 72\n",
      "Train loss: 19.342154\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 74\n",
      "Train loss: 19.340775\n",
      "Train acc: 3.000000\n",
      "EPOCH 76\n",
      "Train loss: 19.339052\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 78\n",
      "Train loss: 19.337546\n",
      "Train acc: 3.000000\n",
      "EPOCH 80\n",
      "Train loss: 19.336098\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 82\n",
      "Train loss: 19.335218\n",
      "Train acc: 3.000000\n",
      "EPOCH 84\n",
      "Train loss: 19.333735\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 86\n",
      "Train loss: 19.333110\n",
      "Train acc: 3.000000\n",
      "EPOCH 88\n",
      "Train loss: 19.331908\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 90\n",
      "Train loss: 19.330913\n",
      "Train acc: 3.000000\n",
      "EPOCH 92\n",
      "Train loss: 19.329896\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 94\n",
      "Train loss: 19.328607\n",
      "Train acc: 3.000000\n",
      "EPOCH 96\n",
      "Train loss: 19.328181\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 98\n",
      "Train loss: 19.327441\n",
      "Train acc: 3.000000\n",
      "EPOCH 100\n",
      "Train loss: 19.326351\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 102\n",
      "Train loss: 19.325526\n",
      "Train acc: 3.000000\n",
      "EPOCH 104\n",
      "Train loss: 19.324937\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 106\n",
      "Train loss: 19.323871\n",
      "Train acc: 3.000000\n",
      "EPOCH 108\n",
      "Train loss: 19.323676\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 110\n",
      "Train loss: 19.323152\n",
      "Train acc: 3.000000\n",
      "EPOCH 112\n",
      "Train loss: 19.322531\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 114\n",
      "Train loss: 19.321977\n",
      "Train acc: 3.000000\n",
      "EPOCH 116\n",
      "Train loss: 19.321348\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 118\n",
      "Train loss: 19.321055\n",
      "Train acc: 3.000000\n",
      "EPOCH 120\n",
      "Train loss: 19.320414\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 122\n",
      "Train loss: 19.319859\n",
      "Train acc: 3.000000\n",
      "EPOCH 124\n",
      "Train loss: 19.319699\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 126\n",
      "Train loss: 19.319215\n",
      "Train acc: 3.000000\n",
      "EPOCH 128\n",
      "Train loss: 19.318807\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 130\n",
      "Train loss: 19.318352\n",
      "Train acc: 3.000000\n",
      "EPOCH 132\n",
      "Train loss: 19.318008\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 134\n",
      "Train loss: 19.317698\n",
      "Train acc: 3.000000\n",
      "EPOCH 136\n",
      "Train loss: 19.317205\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 138\n",
      "Train loss: 19.316828\n",
      "Train acc: 3.000000\n",
      "EPOCH 140\n",
      "Train loss: 19.316756\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 142\n",
      "Train loss: 19.316310\n",
      "Train acc: 3.000000\n",
      "EPOCH 144\n",
      "Train loss: 19.316142\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 146\n",
      "Train loss: 19.315813\n",
      "Train acc: 3.000000\n",
      "EPOCH 148\n",
      "Train loss: 19.315500\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 150\n",
      "Train loss: 19.315193\n",
      "Train acc: 3.000000\n",
      "EPOCH 152\n",
      "Train loss: 19.315039\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 154\n",
      "Train loss: 19.314829\n",
      "Train acc: 3.000000\n",
      "EPOCH 156\n",
      "Train loss: 19.314487\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 158\n",
      "Train loss: 19.314142\n",
      "Train acc: 3.000000\n",
      "EPOCH 160\n",
      "Train loss: 19.314096\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 162\n",
      "Train loss: 19.313800\n",
      "Train acc: 3.000000\n",
      "EPOCH 164\n",
      "Train loss: 19.313640\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 166\n",
      "Train loss: 19.313459\n",
      "Train acc: 3.000000\n",
      "EPOCH 168\n",
      "Train loss: 19.313126\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 170\n",
      "Train loss: 19.312856\n",
      "Train acc: 3.000000\n",
      "EPOCH 172\n",
      "Train loss: 19.312755\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 174\n",
      "Train loss: 19.312627\n",
      "Train acc: 3.000000\n",
      "EPOCH 176\n",
      "Train loss: 19.312314\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 178\n",
      "Train loss: 19.312219\n",
      "Train acc: 3.000000\n",
      "EPOCH 180\n",
      "Train loss: 19.311871\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 182\n",
      "Train loss: 19.311867\n",
      "Train acc: 3.000000\n",
      "EPOCH 184\n",
      "Train loss: 19.311866\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 186\n",
      "Train loss: 19.311671\n",
      "Train acc: 3.000000\n",
      "EPOCH 188\n",
      "Train loss: 19.311410\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 190\n",
      "Train loss: 19.311364\n",
      "Train acc: 3.000000\n",
      "EPOCH 192\n",
      "Train loss: 19.311148\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 194\n",
      "Train loss: 19.311057\n",
      "Train acc: 3.000000\n",
      "EPOCH 196\n",
      "Train loss: 19.310885\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "EPOCH 198\n",
      "Train loss: 19.310713\n",
      "Train acc: 3.000000\n",
      "EPOCH 200\n",
      "Train loss: 19.310748\n",
      "Train acc: 3.000000\n",
      "Predictions: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "Target: tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n"
     ]
    }
   ],
   "source": [
    "run_epoch(epochs, numbarXY1, testMod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#attention visualization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(data, x, y, ax):\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import seaborn objects\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\rcmod.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m palettes\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_theme\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset_defaults\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset_orig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes_style\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_style\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotting_context\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_context\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_palette\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m _style_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes.facecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\palettes.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m husl\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m desaturate, get_color_cycle\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xkcd_rgb, crayons\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_colormap\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\utils.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_rgb\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py:141\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing  \u001b[38;5;66;03m# noqa:PDF015\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     ExcelFile,\n\u001b[0;32m    144\u001b[0m     ExcelWriter,\n\u001b[0;32m    145\u001b[0m     read_excel,\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# parsers\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     read_csv,\n\u001b[0;32m    148\u001b[0m     read_fwf,\n\u001b[0;32m    149\u001b[0m     read_table,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# pickle\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     read_pickle,\n\u001b[0;32m    152\u001b[0m     to_pickle,\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# pytables\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     HDFStore,\n\u001b[0;32m    155\u001b[0m     read_hdf,\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# sql\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     read_sql,\n\u001b[0;32m    158\u001b[0m     read_sql_query,\n\u001b[0;32m    159\u001b[0m     read_sql_table,\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     read_clipboard,\n\u001b[0;32m    162\u001b[0m     read_parquet,\n\u001b[0;32m    163\u001b[0m     read_orc,\n\u001b[0;32m    164\u001b[0m     read_feather,\n\u001b[0;32m    165\u001b[0m     read_gbq,\n\u001b[0;32m    166\u001b[0m     read_html,\n\u001b[0;32m    167\u001b[0m     read_xml,\n\u001b[0;32m    168\u001b[0m     read_json,\n\u001b[0;32m    169\u001b[0m     read_stata,\n\u001b[0;32m    170\u001b[0m     read_sas,\n\u001b[0;32m    171\u001b[0m     read_spss,\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _json_normalize \u001b[38;5;28;01mas\u001b[39;00m json_normalize\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tester\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\api.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mData IO api\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipboards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_clipboard\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     ExcelFile,\n\u001b[0;32m      8\u001b[0m     ExcelWriter,\n\u001b[0;32m      9\u001b[0m     read_excel,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeather_format\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_feather\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgbq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_gbq\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     ExcelFile,\n\u001b[0;32m      3\u001b[0m     ExcelWriter,\n\u001b[0;32m      4\u001b[0m     read_excel,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_odswriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ODSWriter \u001b[38;5;28;01mas\u001b[39;00m _ODSWriter\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_openpyxl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenpyxlWriter \u001b[38;5;28;01mas\u001b[39;00m _OpenpyxlWriter\n",
      "File \u001b[1;32mc:\\Users\\zsq59\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:67\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     62\u001b[0m     IOHandles,\n\u001b[0;32m     63\u001b[0m     get_handle,\n\u001b[0;32m     64\u001b[0m     stringify_path,\n\u001b[0;32m     65\u001b[0m     validate_header_arg,\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     68\u001b[0m     fill_mi_header,\n\u001b[0;32m     69\u001b[0m     get_default_engine,\n\u001b[0;32m     70\u001b[0m     get_writer,\n\u001b[0;32m     71\u001b[0m     maybe_convert_usecols,\n\u001b[0;32m     72\u001b[0m     pop_header_name,\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextParser\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_integer\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1149\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1131\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#attention visualization\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw(data, x, y, ax):\n",
    "    seaborn.heatmap(data, \n",
    "                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n",
    "                    cbar=False, ax=ax)\n",
    "def encoderHeat(testMod,layers,skipby,sent):\n",
    "    for layer in range(0, layers, skipby):\n",
    "        fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(testMod.encoder.layers[layer].self_attn.attn[0, h].data, \n",
    "                sent, sent if h ==0 else [], ax=axs[h])\n",
    "        plt.show()\n",
    "def decoderHeat(testMod,layers,skipby,sent,tgt_sent):   \n",
    "    for layer in range(0, layers, skipby):\n",
    "        fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(testMod.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(tgt_sent)], \n",
    "                tgt_sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "        plt.show()\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(testMod.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(sent)], \n",
    "                sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputbar=numbarXY[0][0]\n",
    "tgtbar=numbarXY[0][1]\n",
    "print(testMod.encoder.layers[0].self_attn.attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss)\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = testMod(num_events, hidden_dim, nhead, nlayer, dim_feedforward, dropout)\n",
    "# for when you leave and come back so you don't have to re-train\n",
    "testMod.load_state_dict(torch.load('./data/modelStates/note2vec1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allpossibletok [[32, 1, 5, 4, 4], [32, 0, 5, 12, 4], [39, 0, 5, 20, 4], [39, 2, 5, 28, 4], [41, 1, 5, 4, 5], [41, 0, 5, 12, 5], [39, 2, 5, 20, 5], [37, 1, 5, 4, 6], [37, 0, 5, 12, 6], [36, 0, 5, 20, 6], [36, 2, 5, 28, 6], [34, 1, 5, 4, 7], [34, 0, 5, 12, 7], [32, 2, 5, 20, 7], [39, 1, 5, 4, 8], [39, 0, 5, 12, 8], [37, 0, 5, 20, 8], [37, 2, 5, 28, 8], [36, 1, 5, 4, 9], [36, 0, 5, 12, 9], [34, 2, 5, 20, 9], [39, 1, 5, 4, 10], [39, 0, 5, 12, 10], [37, 0, 5, 20, 10], [37, 2, 5, 28, 10], [36, 1, 5, 4, 11], [36, 0, 5, 12, 11], [34, 2, 5, 20, 11], [32, 1, 5, 4, 12], [32, 0, 5, 12, 12], [39, 0, 5, 20, 12], [39, 2, 5, 28, 12], [41, 1, 5, 4, 13], [41, 0, 5, 12, 13], [39, 2, 5, 20, 13], [37, 1, 5, 4, 14], [37, 0, 5, 12, 14], [36, 0, 5, 20, 14], [36, 2, 5, 28, 14], [34, 1, 5, 4, 15], [34, 0, 5, 12, 15], [32, 2, 5, 20, 15]]\n",
      "tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5],\n",
      "        [41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]]) tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "generated_song [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5]]\n",
      "iteration 0\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 1.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 1.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 1.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 1.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newbar [6, 7, 8, 9]\n",
      "comp tensor([[37,  1,  5],\n",
      "        [37,  0,  5],\n",
      "        [36,  0,  5],\n",
      "        [36,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5]]\n",
      "iteration 1\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 1.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 1.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 1.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newbar [10, 11, 12]\n",
      "comp tensor([[34,  1,  5],\n",
      "        [34,  0,  5],\n",
      "        [32,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5]]\n",
      "iteration 2\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 1.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 1.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 1.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 1.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newbar [13, 2, 7, 14]\n",
      "comp tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5]]\n",
      "iteration 3\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 1.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 1.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 1.0)]\n",
      "newbar [15, 8, 16]\n",
      "comp tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5]]\n",
      "iteration 4\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 1.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 1.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 1.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 1.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newbar [13, 2, 7, 14]\n",
      "comp tensor([[39,  1,  5],\n",
      "        [39,  0,  5],\n",
      "        [37,  0,  5],\n",
      "        [37,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5]]\n",
      "iteration 5\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 1.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 1.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 1.0)]\n",
      "newbar [15, 8, 16]\n",
      "comp tensor([[36,  1,  5],\n",
      "        [36,  0,  5],\n",
      "        [34,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5]]\n",
      "iteration 6\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 1.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 1.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 1.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 1.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newbar [0, 1, 2, 3]\n",
      "comp tensor([[32,  1,  5],\n",
      "        [32,  0,  5],\n",
      "        [39,  0,  5],\n",
      "        [39,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5]]\n",
      "iteration 7\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 1.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 0.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 1.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newprob 17\n",
      "[(tensor([[32,  1,  5]]), 0.0),\n",
      " (tensor([[32,  0,  5]]), 0.0),\n",
      " (tensor([[39,  0,  5]]), 0.0),\n",
      " (tensor([[39,  2,  5]]), 1.0),\n",
      " (tensor([[41,  1,  5]]), 0.0),\n",
      " (tensor([[41,  0,  5]]), 0.0),\n",
      " (tensor([[37,  1,  5]]), 0.0),\n",
      " (tensor([[37,  0,  5]]), 0.0),\n",
      " (tensor([[36,  0,  5]]), 0.0),\n",
      " (tensor([[36,  2,  5]]), 0.0),\n",
      " (tensor([[34,  1,  5]]), 0.0),\n",
      " (tensor([[34,  0,  5]]), 0.0),\n",
      " (tensor([[32,  2,  5]]), 0.0),\n",
      " (tensor([[39,  1,  5]]), 0.0),\n",
      " (tensor([[37,  2,  5]]), 0.0),\n",
      " (tensor([[36,  1,  5]]), 0.0),\n",
      " (tensor([[34,  2,  5]]), 0.0)]\n",
      "newbar [4, 5, 3]\n",
      "comp tensor([[41,  1,  5],\n",
      "        [41,  0,  5],\n",
      "        [39,  2,  5]])\n",
      "gen [[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5]]\n",
      "newin [[41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5]]\n",
      "[[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "inputbar=X1[0]\n",
    "tgtbar=Y1[0]\n",
    "print(\"allpossibletok\",tokenEvents1)\n",
    "print(inputbar,tgtbar)\n",
    "iter=8\n",
    "lastbarnum=initbarnum\n",
    "sliceidx=0\n",
    "generated_song=[inputbar.tolist()][0]\n",
    "print(\"generated_song\",generated_song)\n",
    "barcount=0\n",
    "for f in range(iter):\n",
    "    print(\"iteration\",f)\n",
    "    prob_tokens = testMod(torch.LongTensor(inputbar).unsqueeze(0)[0], torch.LongTensor(tgtbar).unsqueeze(0)[0], train = False)\n",
    "    prob=testMod.generator(prob_tokens)\n",
    "    #--------------------------------------\n",
    "    idxs=[i for i in range(0,len(src_vocab))]\n",
    "    newprob=[newp.tolist() for newp in prob[0]]\n",
    "    for i in range(len(newprob)):\n",
    "        #first filter\n",
    "        probsum=sum(newprob[i])\n",
    "        probavg=probsum/len(newprob[i])    \n",
    "        for n in range(len(newprob[i])):\n",
    "            if newprob[i][n]<max(newprob[i]):#1.5*probavg\n",
    "                newprob[i][n]=0\n",
    "        #then normalize\n",
    "        probsum=sum(newprob[i])\n",
    "        for j in range(len(newprob[i])):\n",
    "            newprob[i][j]=newprob[i][j]/probsum\n",
    "        print(\"newprob\",len(newprob[i]))\n",
    "        pprint.pprint([(testMod.src_embed[0].unembed([k]),newprob[i][k]) for k in range(len(newprob[i]))])\n",
    "    \n",
    "    newbar=[np.random.choice(idxs,p=normalp) for normalp in newprob]\n",
    "    print(\"newbar\",newbar)\n",
    "    comp=testMod.src_embed[0].unembed(newbar)\n",
    "    print(\"comp\",comp)\n",
    "    final_token=comp.tolist()\n",
    "    generated_song+=final_token\n",
    "    print(\"gen\",generated_song)\n",
    "    tgtbar=Y1[f+1]\n",
    "    inputbar=generated_song[4:] #+generated_song[-1]\n",
    "    print(\"newin\",inputbar)\n",
    "print(generated_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5], [37, 1, 5], [37, 0, 5], [36, 0, 5], [36, 2, 5], [34, 1, 5], [34, 0, 5], [32, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [39, 1, 5], [39, 0, 5], [37, 0, 5], [37, 2, 5], [36, 1, 5], [36, 0, 5], [34, 2, 5], [32, 1, 5], [32, 0, 5], [39, 0, 5], [39, 2, 5], [41, 1, 5], [41, 0, 5], [39, 2, 5]]\n",
      "{5: 8}\n",
      "[[32, 16, 5, 4, 4], [32, 16, 5, 12, 4], [39, 16, 5, 20, 4], [39, 16, 5, 28, 4], [41, 16, 5, 4, 5], [41, 16, 5, 12, 5], [39, 16, 5, 20, 5], [37, 16, 5, 4, 6], [37, 16, 5, 12, 6], [36, 16, 5, 20, 6], [36, 16, 5, 28, 6], [34, 16, 5, 4, 7], [34, 16, 5, 12, 7], [32, 16, 5, 20, 7], [39, 16, 5, 4, 8], [39, 16, 5, 12, 8], [37, 16, 5, 20, 8], [37, 16, 5, 28, 8], [36, 16, 5, 4, 9], [36, 16, 5, 12, 9], [34, 16, 5, 20, 9], [39, 16, 5, 4, 10], [39, 16, 5, 12, 10], [37, 16, 5, 20, 10], [37, 16, 5, 28, 10], [36, 16, 5, 4, 11], [36, 16, 5, 12, 11], [34, 16, 5, 20, 11], [32, 16, 5, 4, 12], [32, 16, 5, 12, 12], [39, 16, 5, 20, 12], [39, 16, 5, 28, 12], [41, 16, 5, 4, 13], [41, 16, 5, 12, 13], [39, 16, 5, 20, 13]]\n"
     ]
    }
   ],
   "source": [
    "print(generated_song)\n",
    "lastbarnum=initbarnum\n",
    "lastpos=initpos\n",
    "DP=preprocessing.DPmapping([f[:-1] for f in tokenEvents1])\n",
    "print(DP)\n",
    "for i in range(len(generated_song)):\n",
    "    generated_song[i]+=[lastpos]\n",
    "    lastpos+=DP[generated_song[i][-2]]\n",
    "    if generated_song[i][1]==2:\n",
    "        generated_song[i]+=[lastbarnum]\n",
    "        lastbarnum+=1\n",
    "        lastpos=initpos\n",
    "    else:\n",
    "        generated_song[i]+=[lastbarnum]\n",
    "    generated_song[i][1]=16\n",
    "\n",
    "print(generated_song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmidi=preprocessing.tokenizer.tokens_to_midi([generated_song])\n",
    "testmidi.dump('test_clean.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
